{
module NeuralLanguageLex
open System
open Microsoft.FSharp.Text.Lexing

let lexeme = Lexing.LexBuffer<_>.LexemeString
let cultureInfo = System.Globalization.CultureInfo.CreateSpecificCulture("en-us")
let extractIndex (text:string) = Convert.ToInt32(text.Split([|"ATT"; "INST"|], System.StringSplitOptions.RemoveEmptyEntries).[0])

// Apro il modulo del parser per avere accesso ai token definiti li'
open NeuralLanguageParser

let keywords = [ 
    "PREPROCESSING", PREPROC;
    "TRAINING", TRAININGKEY;
    "VALIDATION", VALIDATIONKEY;
    "ATTRIBUTE", ATTKEY;
    "INSTANCE", INSTKEY;
    "NETWORK", NETWORKKEY;
    "TRAINING_SET", TRAINSETKEY;
    "CLASS_ATTRIBUTE", CLASSKEY;
    "LOAD_TRAINING", LOADTRAIN;
    "LOAD_NETWROK", LOADNET] |> Map.ofList
}

let char				= ['a'-'z' 'A'-'Z']
let digit				= ['0'-'9']
let whitespace			= [' ' '\t']
let newline				= "\n\r" | '\n' | '\r'
let identifier			= char(char|digit|'_')*
let attIdentifier		= "ATT"(digit)+
let instIdentifier		= "INST"(digit)+

let DoubleNumber = digit+ ('.' digit*)?(['e''E']['-']?digit+)?
let function = "exp" | "sin" | "cos" | "acos" | "asin" | "tan" | "atan" | "sinh" | "tanh" | "log" | "ln" | "floor" | "ceil" | "sqrt" | "abs"
let aggregateFunction = "mean" | "min" | "max" | "sd" | "sum" | "sumsquared"
let boolLiteral = "true" | "false"

// rules
rule tokenize = parse
	| whitespace	{ tokenize lexbuf }
	| newline		{ lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf }
	
	// Bool literal
	| boolLiteral		{ BOOLEAN(System.Boolean.Parse(lexeme lexbuf))}

	// Operators
	| function			{ FUNCTION(lexeme lexbuf) }	
	| aggregateFunction { AGGFUNCTION(lexeme lexbuf) }
	| "sumOfProducts"	{ SUMOFPRODUCTS }
	| "+"				{ PLUS  }
	| "-"				{ MINUS }
	| "*"				{ ASTER }
	| "/"				{ SLASH }
	| "^"				{ POW }
	| '<'				{ LT }
	| "<="				{ LTE }
	| '>'				{ GT }
	| ">="				{ GTE }
	| "=="				{ EQ }
	| "!="				{ NOTEQ }
	| "!"				{ NOT }
	| "&&"				{ AND }
	| "||"				{ OR }

	// Identifiers
	| attIdentifier	{ ATTINDEX(extractIndex (lexeme lexbuf)) }											// Le regole fanno match dall'alto in basso, quindi questa va prima di identifier
	| instIdentifier{ INSTINDEX(extractIndex (lexeme lexbuf)) }													// stesso discorso di sopra
	| "\""			{ STRING(string lexbuf.StartPos "" lexbuf) }
 	| identifier	{ match keywords.TryFind(lexeme lexbuf) with
                        | Some(token) -> token
                        | None -> STRING(lexeme lexbuf) }

	// Numeric constants
	| DoubleNumber		{ DOUBLE (Double.Parse(lexeme lexbuf, cultureInfo)) }

	| ','			{ COMMA }
	| '('			{ LP }
	| ')'			{ RP }
	| '{'			{ LCB }
	| '}'			{ RCB }
	| '['			{ LB }
	| ']'			{ RB }
	| ':'			{ COLON }
	| ".."			{ DOTS }
	| ';'			{ SEMICOLON }
	| eof			{ EOF }
	| _				{ failwithf "unrecognized input: '%s'" (lexeme lexbuf) }

and string pos s = parse			// Accumulo la stringa in s fino alla chiusura (") e mi porto avanti la posizione iniziale per il messaggio di errore
	| "\""		{ s }
	| eof		{ failwithf "end of file in string started at or near line %d, character %d \n String : '%s'\n" pos.Line pos.Column s }
	| _			{ string pos (s + (lexeme lexbuf)) lexbuf }

