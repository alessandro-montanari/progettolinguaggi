{
module NeuralLanguageLex
open System
open Microsoft.FSharp.Text.Lexing

let lexeme = Lexing.LexBuffer<_>.LexemeString
let cultureInfo = System.Globalization.CultureInfo.CreateSpecificCulture("en-us")
let extractId (text:string) = text.Split([|"ATT"; "INST"|], System.StringSplitOptions.RemoveEmptyEntries).[0]

// Apro il modulo del parser per avere accesso ai token definiti li'
open NeuralLanguageParser

let keywords = [ 
    "PREPROCESSING", PREPROC;
    "TRAINING", TRAININGKEY;
    "VALIDATION", VALIDATION;
    "WHIT_PLOT", PLOT; 
    "ATTRIBUTE", ATTKEY;
    "INSTANCE", INSTKEY;
    "TRAINING_SET", TRAINSETKEY;
    "WITH_PLOT", PLOTKEY] |> Map.ofList

let mathOps = 
    [ 
        "+", PLUS;
        "-", MINUS;
        "*", TIMES;
        "/", FRAC;
        "^", POW ] |> Map.ofList

let logicOps =
    [
        "&&", AND;
        "||", OR;
        "!", NOT;
        "true", TRUE;
        "false", FALSE;
    ] |> Map.ofList

let functions =
    [
        "sin", SIN;
        "cos", COS;
        "tan", TAN;
        "atan", ATAN;
        "log", LOG;
        "ln", LN;
        "floor", FLOOR;
        "ceil", CEIL;
        "sqrt", SQRT;
        "mean", MEAN;
        "sd", SD;
        "min", MIN;
        "max", MAX;
        "sum", SUM;
        "sumsquared", SUMSQUARED
    ] |> Map.ofList

let relOps = 
    [
        "<", LT;
        "<=", LTE;
        ">", GT;
        ">=", GTE;
        "==", EQ;
        "!=", NOTEQ
    ] |> Map.ofList
}

let char				= ['a'-'z' 'A'-'Z']
let digit				= ['0'-'9']
let number				= digit+ ('.' digit*)?
let whitespace			= [' ' '\t']
let newline				= "\n\r" | '\n' | '\r'
let identifier			= char(char|digit|'_')*
let attIdentifier		= "ATT"(digit)+
let instIdentifier		= "INST"(digit)+
let mathOp				= '+' | '-' | '*' | '/' | '^'
let logicOp				= "&&" | "||" | '!' | "true" | "false"
let function			= "sin" | "cos" | "tan" | "atan" | "log" | "ln" | "floor" | "ceil" | "sqrt" | "mean" | "min" | "max" | "sd" | "sum" | "sumsquared"
let relOp				= '<' | "<=" | '>' | ">=" | "==" | "!="

// rules
rule tokenize = parse
	| whitespace	{ tokenize lexbuf }
	| newline		{ lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf }
	| mathOp		{ mathOps.[lexeme lexbuf] }
	| number		{ NUMBER(Convert.ToDouble((lexeme lexbuf), cultureInfo)) }
	| attIdentifier	{ ATTID(extractId (lexeme lexbuf)) }											// Le regole fanno match dall'alto in basso, quindi questa va prima di identifier
	| instIdentifier{ INSTID(extractId (lexeme lexbuf)) }
	| function		{ functions.[lexeme lexbuf] }													// stesso discorso di sopra
	| logicOp		{ logicOps.[lexeme lexbuf] }
	| "\""			{ ID(string lexbuf.StartPos "" lexbuf) }
 	| identifier	{ match keywords.TryFind(lexeme lexbuf) with
                        | Some(token) -> token
                        | None -> ID(lexeme lexbuf) }
	| relOp			{ relOps.[lexeme lexbuf] }
	| ','			{ COMMA }
	| '('			{ LP }
	| ')'			{ RP }
	| '{'			{ LCB }
	| '}'			{ RCB }
	| '['			{ LB }
	| ']'			{ RB }
	| ':'			{ COLON }
	| ".."			{ DOTS }
	| ';'			{ SEMICOLON }
	| eof			{ EOF }
	| _				{ failwithf "unrecognized input: '%s'" (lexeme lexbuf) }

and string pos s = parse			// Accumulo la stringa in s fino alla chiusura (") e mi porto avanti la posizione iniziale per il messaggio di errore
	| "\""		{ s }
	| eof		{ failwithf "end of file in string started at or near line %d, character %d \n String : '%s'\n" pos.Line pos.Column s }
	| _			{ string pos (s + (lexeme lexbuf)) lexbuf }

